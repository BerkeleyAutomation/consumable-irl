# YAML file for experiments
# Current setup has _no_ penalization for hitting walls
exp_id: 1

results_path: './Results/Experiments/PST/iFDD'

experiment: rlpy.Experiments.Experiment

# domain: rlpy.Domains.Pinball

domain: rlpy.Domains.PST
domain_params:
    NUM_UAV: 4
#     goalArray:
#         - [0.8, 0.1]
#         - [0.9, 0.2]
#         - [0.9, 0.4]
#     noise: 0.1

initrep: rlpy.Representations.IndependentDiscretization
initrep_params:
    # domain: implicit
    discretization: 20


representation: rlpy.Representations.iFDD
representation_params:
    # domain: implicit
    # initial_rep: implicit
    sparsify: True
    useCache: True 


discover_threshold: 150

policy: rlpy.Policies.eGreedy
policy_params:
    # representation: also implicit
    epsilon: 0.1

agent: rlpy.Agents.Q_Learning
agent_params:
    # - representation
    # - policy
    # - discount factor = domain.discount_factor = 0.9
    initial_learn_rate: 0.4
    lambda_: 0.9
    learn_rate_decay_mode: 'boyan'
    boyan_N0: 1000

checks_per_policy: 5
max_steps: 300000
num_policy_checks: 10
